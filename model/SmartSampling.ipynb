{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "\n",
    "from smartsampling import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if device==\"cuda\":\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = pickle.load(open('data/node_features.pkl', 'rb'))\n",
    "# coauthors_matrix = pickle.load(open('data/coauthors_matrix.pkl', 'rb'))\n",
    "# shortest_path_length = pickle.load(open('data/shortest_path_length.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = np.array(list(node_features.values()))\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(text_features)\n",
    "emb_features = pca.transform(text_features)\n",
    "\n",
    "nnodes = text_features.shape[0]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# G = nx.from_scipy_sparse_matrix(coauthors_matrix)\n",
    "# G = list(G.subgraph(c) for c in nx.connected_components(G))[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_space = [0.2, 0.5, 1, 2, 5]\n",
    "q_space = [0.2, 0.5, 1, 2, 5]\n",
    "c_space = [1, 2, 3, 4, 5]\n",
    "\n",
    "nsamplers = 1000\n",
    "lr = 0.005\n",
    "weight_decay = 5e-4\n",
    "dropout = 0.4\n",
    "nepoch = 100\n",
    "penalty = 3e-4\n",
    "\n",
    "ratio = 0.1\n",
    "nfold = 1 #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold in range(nfold):\n",
    "#     train_G, prediction_links = prepare(G.copy(), ratio)\n",
    "#     pickle.dump((train_G, prediction_links), open('link_prediction/input_{}.pkl'.format(fold+1), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#     print(fold+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fold: 1\n",
      "Epoch: 20, Gain: 9.0649, Time: 111.5093s\n",
      "Epoch: 40, Gain: 11.2474, Time: 98.7959s\n",
      "Epoch: 60, Gain: 16.1540, Time: 98.5421s\n",
      "Epoch: 80, Gain: 19.2911, Time: 98.4587s\n",
      "Epoch: 100, Gain: 19.2616, Time: 100.1872s\n",
      "Fold: 1, Acc: 0.5047, F1: 0.5584\n",
      "\n",
      "Final results: Acc = 0.5047 +- 0.0000, F1 = 0.5584 +- 0.0000\n"
     ]
    }
   ],
   "source": [
    "lp_results = []\n",
    "save_results = []\n",
    "\n",
    "for fold in range(1, nfold+1):\n",
    "    print(\"Start Fold: {}\".format(fold))\n",
    "    \n",
    "    train_G, prediction_links = pickle.load(open('link_prediction/input_{}.pkl'.format(fold), 'rb'))\n",
    "    \n",
    "    model = SmartSampling(text_features, emb_features, p_space, q_space, c_space, \n",
    "                      nnodes, nsamplers, lr, weight_decay, dropout, device, \n",
    "                      train_G)\n",
    "    embeddings = model.train(nepoch, penalty)\n",
    "    torch.save(model.state_dict(), 'link_prediction/model_{}.pkl'.format(fold))\n",
    "    pickle.dump(embeddings, open('link_prediction/embeddings_{}.pkl'.format(fold), 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    lp_acc, lp_f1 = lp_evaluate(embeddings.cpu().numpy(), prediction_links)\n",
    "    lp_results.append((lp_acc, lp_f1))\n",
    "    save_results.append(\"Fold: {}, Acc: {:.4f}, F1: {:.4f}\".format(fold, lp_acc, lp_f1))\n",
    "    print(save_results[-1])\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "analysis = []\n",
    "results = np.array(lp_results)\n",
    "for i in range(results.shape[1]):\n",
    "    analysis.append((np.mean(results[:,i]), np.std(results[:,i])))\n",
    "\n",
    "print()\n",
    "final_results = \"Final results: \" +\\\n",
    "      \"Acc = {:.4f} +- {:.4f}, \".format(analysis[0][0], analysis[0][1]) +\\\n",
    "      \"F1 = {:.4f} +- {:.4f}\".format(analysis[1][0], analysis[1][1])\n",
    "print(final_results)\n",
    "\n",
    "parameters = \"Parameters: \" +\\\n",
    "        \"nepoch: {}, \".format(nepoch) +\\\n",
    "        \"nsampler: {}, \".format(nsamplers) +\\\n",
    "        \"penalty: {}\".format(penalty)\n",
    "\n",
    "with open('train_link_prediction.txt','a') as file:\n",
    "    file.write(parameters+'\\n')\n",
    "    for save_result in save_results:\n",
    "        file.write(save_result+'\\n')\n",
    "    file.write(final_results+'\\n')\n",
    "    file.write('\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
